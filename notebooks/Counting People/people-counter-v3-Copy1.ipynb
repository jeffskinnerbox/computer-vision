{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MassMutual People Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show People Counting Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import numpy\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "source = {\n",
    "    \"path\": \"/home/jeff/Jupyter-Notebooks/videos\",\n",
    "    \"file\": \"People-Walking-Shot-From-Above.mp4\",\n",
    "    \"device\": \"\"\n",
    "}\n",
    "\n",
    "sink = {\n",
    "    \"path\": \"/home/jeff/Jupyter-Notebooks/videos\",\n",
    "    \"file\": \"output.mp4\",\n",
    "    \"device\": \"\"\n",
    "}\n",
    "\n",
    "\n",
    "class MyPerson:\n",
    "    tracks = []\n",
    "\n",
    "    def __init__(self, i, xi, yi, max_age):\n",
    "        self.i = i\n",
    "        self.x = xi\n",
    "        self.y = yi\n",
    "        self.tracks = []\n",
    "        self.R = randint(0, 255)\n",
    "        self.G = randint(0, 255)\n",
    "        self.B = randint(0, 255)\n",
    "        self.done = False\n",
    "        self.state = '0'\n",
    "        self.age = 0\n",
    "        self.max_age = max_age\n",
    "        self.dir = None\n",
    "\n",
    "    def getRGB(self):\n",
    "        return (self.R, self.G, self.B)\n",
    "\n",
    "    def getTracks(self):\n",
    "        return self.tracks\n",
    "\n",
    "    def getId(self):\n",
    "        return self.i\n",
    "\n",
    "    def getState(self):\n",
    "        return self.state\n",
    "\n",
    "    def getDir(self):\n",
    "        return self.dir\n",
    "\n",
    "    def getX(self):\n",
    "        return self.x\n",
    "\n",
    "    def getY(self):\n",
    "        return self.y\n",
    "\n",
    "    def updateCoords(self, xn, yn):\n",
    "        self.age = 0\n",
    "        self.tracks.append([self.x, self.y])\n",
    "        self.x = xn\n",
    "        self.y = yn\n",
    "\n",
    "    def setDone(self):\n",
    "        self.done = True\n",
    "\n",
    "    def timedOut(self):\n",
    "        return self.done\n",
    "\n",
    "    def going_UP(self, mid_start, mid_end):\n",
    "        if len(self.tracks) >= 2:\n",
    "            if self.state == '0':\n",
    "                if self.tracks[-1][1] < mid_end and self.tracks[-2][1] >= mid_end:                       #noqa\n",
    "                    state = '1'\n",
    "                    self.dir = 'up'\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def going_DOWN(self, mid_start, mid_end):\n",
    "        if len(self.tracks) >= 2:\n",
    "            if self.state == '0':\n",
    "                if self.tracks[-1][1] > mid_start and self.tracks[-2][1] <= mid_start:                   #noqa\n",
    "                    state = '1'\n",
    "                    self.dir = 'down'\n",
    "                    return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def age_one(self):\n",
    "        self.age += 1\n",
    "        if self.age > self.max_age:\n",
    "            self.done = True\n",
    "        return True\n",
    "\n",
    "\n",
    "class MultiPerson:\n",
    "    def __init__(self, persons, xi, yi):\n",
    "        self.persons = persons\n",
    "        self.x = xi\n",
    "        self.y = yi\n",
    "        self.tracks = []\n",
    "        self.R = randint(0, 255)\n",
    "        self.G = randint(0, 255)\n",
    "        self.B = randint(0, 255)\n",
    "        self.done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "import json\n",
    "import ts_dweepy                           # https://pypi.python.org/pypi/dweepy/\n",
    "\n",
    "\n",
    "class trace_mess:\n",
    "\n",
    "    def __init__(self, src):\n",
    "        self.run_stamp = {\n",
    "            \"mess-type\": \"EXEC\",\n",
    "            \"mess-format\": \"0.0.2\",\n",
    "            \"run-id\": str(uuid.uuid4()),\n",
    "            \"run-time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()),\n",
    "            \"run-status\": \"start\",\n",
    "            \"run-platform\": \"Desktop-Jupyter\",\n",
    "            \"run-source\": src,\n",
    "            \"version\": {\n",
    "                \"algorithm\": \"0.0.3\",\n",
    "                \"cv2\": cv2.__version__\n",
    "            }\n",
    "        }\n",
    "        print(json.dumps(self.run_stamp))\n",
    "        ts_dweepy.dweet_for(self.run_stamp[\"run-platform\"], {\"mess-text\": self.run_stamp})\n",
    "\n",
    "    def start(self):\n",
    "        self.run_stamp[\"run-status\"] = \"start\"\n",
    "        self.run_stamp[\"run-time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())    #noqa\n",
    "        print(json.dumps(self.run_stamp))\n",
    "\n",
    "    def stop(self):\n",
    "        self.run_stamp[\"run-status\"] = \"stop\"\n",
    "        self.run_stamp[\"run-time\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())    #noqa\n",
    "        print(json.dumps(self.run_stamp))\n",
    "        ts_dweepy.dweet_for(self.run_stamp[\"run-platform\"], {\"mess-text\": self.run_stamp})\n",
    "\n",
    "    def error(self, mess):\n",
    "        print(json.dumps({\"mess-type\": \"ERROR\",\"run-id\": self.run_stamp[\"run-id\"], \"mess-text\": mess}))       #noqa\n",
    "\n",
    "    def warning(self, mess):\n",
    "        print(json.dumps({\"mess-type\": \"WARNING\",\"run-id\": self.run_stamp[\"run-id\"], \"mess-text\": mess}))     #noqa\n",
    "\n",
    "    def info(self, mess):\n",
    "        print(json.dumps({\"mess-type\": \"INFO\",\"run-id\": self.run_stamp[\"run-id\"], \"mess-text\": mess}))        #noqa\n",
    "\n",
    "    def feature(self, mess):\n",
    "        print(json.dumps({\"mess-type\": \"FEATURE\",\"run-id\": self.run_stamp[\"run-id\"], \"mess-text\": mess}))     #noqa\n",
    "        ts_dweepy.dweet_for(self.run_stamp[\"run-platform\"], {\"mess-type\": \"FEATURE\", \"run-id\": self.run_stamp[\"run-id\"], \"mess-text\": mess})     #noqa    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input and Output Counters\n",
    "cnt_up = 0\n",
    "cnt_down = 0\n",
    "\n",
    "# Video Source\n",
    "# cap = cv2.VideoCapture(0)\n",
    "cap = cv2.VideoCapture(source[\"path\"] + '/' + source[\"file\"])\n",
    "\n",
    "# create trace message object\n",
    "trc = trace_mess(source[\"file\"])\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened() is False):\n",
    "    trc.error(\"Error opening video stream or file\")\n",
    "    trc.stop()\n",
    "    exit\n",
    "\n",
    "# Get current width and height of frame\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)               # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)             # float\n",
    "trc.info({\"frame\": {\"width\": width, \"height\": height,\n",
    "                    \"fps\": cap.get(cv2.CAP_PROP_FPS),\n",
    "                    \"count\": cap.get(cv2.CAP_PROP_FRAME_COUNT)}})\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "# fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "fourcc = cv2.VideoWriter_fourcc('M', 'P', '4', 'V')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'a\\0\\0\\0')\n",
    "out = cv2.VideoWriter(sink[\"path\"] + '/' + sink[\"file\"], fourcc, 20.0, (int(width), int(height)))   #noqa                     #noqa\n",
    "\n",
    "# Video properties\n",
    "# cap.set(3, 160) # Width\n",
    "# cap.set(4, 120) # Height\n",
    "\n",
    "# Prints the capture properties to console\n",
    "# for i in range(19):\n",
    "#    print(i, cap.get(i))\n",
    "\n",
    "w = cap.get(3)\n",
    "h = cap.get(4)\n",
    "frameArea = h*w\n",
    "areaTH = frameArea/250\n",
    "\n",
    "# Input / output lines\n",
    "line_up = int(2*(h/5))\n",
    "line_down = int(3*(h/5))\n",
    "\n",
    "up_limit = int(1*(h/5))\n",
    "down_limit = int(4*(h/5))\n",
    "\n",
    "trc.info({\"area threshold\": areaTH, \"lines\":{\"red y axis\": str(line_down), \"blue y axis\": str(line_up)}})     #noqa\n",
    "\n",
    "line_down_color = (255, 0, 0)\n",
    "line_up_color = (0, 0, 255)\n",
    "pt1 = [0, line_down]\n",
    "pt2 = [w, line_down]\n",
    "pts_L1 = numpy.array([pt1, pt2], numpy.int32)\n",
    "pts_L1 = pts_L1.reshape((-1, 1, 2))\n",
    "pt3 = [0, line_up]\n",
    "pt4 = [w, line_up]\n",
    "pts_L2 = numpy.array([pt3, pt4], numpy.int32)\n",
    "pts_L2 = pts_L2.reshape((-1, 1, 2))\n",
    "\n",
    "pt5 = [0, up_limit]\n",
    "pt6 = [w, up_limit]\n",
    "pts_L3 = numpy.array([pt5, pt6], numpy.int32)\n",
    "pts_L3 = pts_L3.reshape((-1, 1, 2))\n",
    "pt7 = [0, down_limit]\n",
    "pt8 = [w, down_limit]\n",
    "pts_L4 = numpy.array([pt7, pt8], numpy.int32)\n",
    "pts_L4 = pts_L4.reshape((-1, 1, 2))\n",
    "\n",
    "# Background subtractor\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n",
    "\n",
    "# Structural elements for morphogic filters\n",
    "kernelOp = numpy.ones((3, 3), numpy.uint8)\n",
    "kernelOp2 = numpy.ones((5, 5), numpy.uint8)\n",
    "kernelCl = numpy.ones((11, 11), numpy.uint8)\n",
    "\n",
    "# Variables\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "persons = []\n",
    "max_p_age = 5\n",
    "pid = 1\n",
    "\n",
    "while(cap.isOpened()):\n",
    "# for image in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):                 #noqa\n",
    "    # Read an image from the video source\n",
    "    ret, frame = cap.read()\n",
    "#     frame = image.array\n",
    "\n",
    "    for i in persons:\n",
    "        i.age_one()   # age every person one frame\n",
    "    #########################\n",
    "    #   PRE-PROCESSING      #\n",
    "    #########################\n",
    "\n",
    "    # Apply subtraction of background\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    fgmask2 = fgbg.apply(frame)\n",
    "\n",
    "    # Binary to remove shadows (gray color)\n",
    "    try:\n",
    "        ret, imBin = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "        ret, imBin2 = cv2.threshold(fgmask2, 200, 255, cv2.THRESH_BINARY)\n",
    "        # Opening (erode-> dilate) to remove noise\n",
    "        mask = cv2.morphologyEx(imBin, cv2.MORPH_OPEN, kernelOp)\n",
    "        mask2 = cv2.morphologyEx(imBin2, cv2.MORPH_OPEN, kernelOp)\n",
    "        # Closing (dilate -> erode) to join white regions\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernelCl)\n",
    "        mask2 = cv2.morphologyEx(mask2, cv2.MORPH_CLOSE, kernelCl)\n",
    "    except:\n",
    "        trc.info({\"total count\": {\"up\": cnt_up, \"down\": cnt_down}})\n",
    "        trc.stop()\n",
    "        break\n",
    "    #################\n",
    "    #    CONTOURS   #\n",
    "    #################\n",
    "\n",
    "    # RETR_EXTERNAL returns only extreme outer flags. All child contours are left behind.                #noqa\n",
    "    _, contours0, hierarchy = cv2.findContours(mask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)        #noqa\n",
    "    for cnt in contours0:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > areaTH:\n",
    "            #################\n",
    "            #   TRACKING    #\n",
    "            #################\n",
    "\n",
    "            # Missing add conditions for multipersons, outputs and screen inputs              #noqa\n",
    "\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "            new = True\n",
    "            if cy in range(up_limit, down_limit):\n",
    "                for i in persons:\n",
    "                    if abs(cx-i.getX()) <= w and abs(cy-i.getY()) <= h:\n",
    "                        # the object is near one already detected before\n",
    "                        new = False\n",
    "                        i.updateCoords(cx, cy)   # update coordinates in the object and resets age     #noqa\n",
    "                        if i.going_UP(line_down, line_up) is True:\n",
    "                            cnt_up += 1\n",
    "                            trc.feature({\"object\":{\"id\":i.getId(),\"direction\": \"up\", \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())}})    #noqa\n",
    "                        elif i.going_DOWN(line_down, line_up) is True:\n",
    "                            cnt_down += 1\n",
    "                            trc.feature({\"object\":{\"id\":i.getId(),\"direction\": \"down\", \"time\": time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())}})    #noqa\n",
    "                        break\n",
    "                    if i.getState() == '1':\n",
    "                        if i.getDir() == 'down' and i.getY() > down_limit:\n",
    "                            i.setDone()\n",
    "                        elif i.getDir() == 'up' and i.getY() < up_limit:\n",
    "                            i.setDone()\n",
    "                    if i.timedOut():\n",
    "                        # remove from the list persons\n",
    "                        index = persons.index(i)\n",
    "                        persons.pop(index)\n",
    "                        del i     # free memory of i\n",
    "                if new is True:\n",
    "                    p = MyPerson(pid, cx, cy, max_p_age)\n",
    "                    persons.append(p)\n",
    "                    pid += 1\n",
    "            #################\n",
    "            #   DRAWINGS    #\n",
    "            #################\n",
    "            cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)\n",
    "            img = cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            # cv2.drawContours(frame, cnt, -1, (0, 255, 0), 3)\n",
    "\n",
    "    # END for cnt in contours0\n",
    "\n",
    "    #########################\n",
    "    # DRAWING TRAJECTORIES  #\n",
    "    #########################\n",
    "    for i in persons:\n",
    "        # if len(i.getTracks()) >= 2:\n",
    "            # pts = numpy.array(i.getTracks(), numpy.int32)\n",
    "            # pts = pts.reshape((-1, 1, 2))\n",
    "            # frame = cv2.polylines(frame, [pts], False, i.getRGB())\n",
    "        # if i.getId() == 9:\n",
    "            # print(str(i.getX()), ', ', str(i.getY()))\n",
    "        cv2.putText(frame, str(i.getId()), (i.getX(), i.getY()), font, 0.3, i.getRGB(), 1, cv2.LINE_AA)  #noqa\n",
    "\n",
    "    #################\n",
    "    #     IMAGES    #\n",
    "    #################\n",
    "    str_up = 'UP: ' + str(cnt_up)\n",
    "    str_down = 'DOWN: ' + str(cnt_down)\n",
    "    frame = cv2.polylines(frame, [pts_L1], False, line_down_color, thickness=2)\n",
    "    frame = cv2.polylines(frame, [pts_L2], False, line_up_color, thickness=2)\n",
    "    frame = cv2.polylines(frame, [pts_L3], False, (255, 255, 255), thickness=1)\n",
    "    frame = cv2.polylines(frame, [pts_L4], False, (255, 255, 255), thickness=1)\n",
    "    cv2.putText(frame, str_up, (10, 40), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)  #noqa\n",
    "    cv2.putText(frame, str_up, (10, 40), font, 0.5, (0, 0, 255), 1, cv2.LINE_AA)  #noqa\n",
    "    cv2.putText(frame, str_down, (10, 90), font, 0.5, (255, 255, 255), 2, cv2.LINE_AA)  #noqa\n",
    "    cv2.putText(frame, str_down, (10, 90), font, 0.5, (255, 0, 0), 1, cv2.LINE_AA)  #noqa\n",
    "\n",
    "    cv2.imshow('Frame', frame)\n",
    "    # cv2.imshow('Mask', mask)\n",
    "\n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    "\n",
    "    # pre-set ESC or 'q' to exit\n",
    "    k = cv2.waitKey(20) & 0xFF\n",
    "    if k == 27 or k == ord('q'):\n",
    "        break\n",
    "# END while(cap.isOpened())\n",
    "\n",
    "    #################\n",
    "    #   CLEANING    #\n",
    "    #################\n",
    "trc.stop()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"videos/output.mp4\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=\"596\" height=\"336\" controls>\n",
    "  <source src=\"videos/output.mp4\" type=\"video/mp4\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* [People Counter blog by Federico Mejia Barajas](http://www.femb.com.mx/people-counter/people-counter-9-counting/)\n",
    "* [Video of FEMB in action](https://www.youtube.com/watch?time_continue=9&v=aEcBnD80nLg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
