{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_keras_server.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# Start the server:\n",
    "# \tpython run_keras_server.py\n",
    "# Submit a request via cURL:\n",
    "# \tcurl -X POST -F image=@jemma.png 'http://localhost:5000/predict'\n",
    "# Submita a request via Python:\n",
    "#\tpython simple_request.py\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import imagenet_utils\n",
    "from threading import Thread\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "import flask\n",
    "import redis\n",
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# initialize constants used to control image spatial dimensions and\n",
    "# data type\n",
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_CHANS = 3\n",
    "IMAGE_DTYPE = \"float32\"\n",
    "\n",
    "# initialize constants used for server queuing\n",
    "IMAGE_QUEUE = \"image_queue\"\n",
    "BATCH_SIZE = 32\n",
    "SERVER_SLEEP = 0.25\n",
    "CLIENT_SLEEP = 0.25\n",
    "\n",
    "# initialize our Flask application, Redis server, and Keras model\n",
    "app = flask.Flask(__name__)\n",
    "db = redis.StrictRedis(host=\"localhost\", port=6379, db=0)\n",
    "model = None\n",
    "\n",
    "def base64_encode_image(a):\n",
    "\t# base64 encode the input NumPy array\n",
    "\treturn base64.b64encode(a).decode(\"utf-8\")\n",
    "\n",
    "def base64_decode_image(a, dtype, shape):\n",
    "\t# if this is Python 3, we need the extra step of encoding the\n",
    "\t# serialized NumPy string as a byte object\n",
    "\tif sys.version_info.major == 3:\n",
    "\t\ta = bytes(a, encoding=\"utf-8\")\n",
    "\n",
    "\t# convert the string to a NumPy array using the supplied data\n",
    "\t# type and target shape\n",
    "\ta = np.frombuffer(base64.decodestring(a), dtype=dtype)\n",
    "\ta = a.reshape(shape)\n",
    "\n",
    "\t# return the decoded image\n",
    "\treturn a\n",
    "\n",
    "def prepare_image(image, target):\n",
    "\t# if the image mode is not RGB, convert it\n",
    "\tif image.mode != \"RGB\":\n",
    "\t\timage = image.convert(\"RGB\")\n",
    "\n",
    "\t# resize the input image and preprocess it\n",
    "\timage = image.resize(target)\n",
    "\timage = img_to_array(image)\n",
    "\timage = np.expand_dims(image, axis=0)\n",
    "\timage = imagenet_utils.preprocess_input(image)\n",
    "\n",
    "\t# return the processed image\n",
    "\treturn image\n",
    "\n",
    "def classify_process():\n",
    "\t# load the pre-trained Keras model (here we are using a model\n",
    "\t# pre-trained on ImageNet and provided by Keras, but you can\n",
    "\t# substitute in your own networks just as easily)\n",
    "\tprint(\"* Loading model...\")\n",
    "\tmodel = ResNet50(weights=\"imagenet\")\n",
    "\tprint(\"* Model loaded\")\n",
    "\n",
    "\t# continually pool for new images to classify\n",
    "\twhile True:\n",
    "\t\t# attempt to grab a batch of images from the database, then\n",
    "\t\t# initialize the image IDs and batch of images themselves\n",
    "\t\tqueue = db.lrange(IMAGE_QUEUE, 0, BATCH_SIZE - 1)\n",
    "\t\timageIDs = []\n",
    "\t\tbatch = None\n",
    "\n",
    "\t\t# loop over the queue\n",
    "\t\tfor q in queue:\n",
    "\t\t\t# deserialize the object and obtain the input image\n",
    "\t\t\tq = json.loads(q.decode(\"utf-8\"))\n",
    "\t\t\timage = base64_decode_image(q[\"image\"], IMAGE_DTYPE,\n",
    "\t\t\t\t(1, IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANS))\n",
    "\n",
    "\t\t\t# check to see if the batch list is None\n",
    "\t\t\tif batch is None:\n",
    "\t\t\t\tbatch = image\n",
    "\n",
    "\t\t\t# otherwise, stack the data\n",
    "\t\t\telse:\n",
    "\t\t\t\tbatch = np.vstack([batch, image])\n",
    "\n",
    "\t\t\t# update the list of image IDs\n",
    "\t\t\timageIDs.append(q[\"id\"])\n",
    "\n",
    "\t\t# check to see if we need to process the batch\n",
    "\t\tif len(imageIDs) > 0:\n",
    "\t\t\t# classify the batch\n",
    "\t\t\tprint(\"* Batch size: {}\".format(batch.shape))\n",
    "\t\t\tpreds = model.predict(batch)\n",
    "\t\t\tresults = imagenet_utils.decode_predictions(preds)\n",
    "\n",
    "\t\t\t# loop over the image IDs and their corresponding set of\n",
    "\t\t\t# results from our model\n",
    "\t\t\tfor (imageID, resultSet) in zip(imageIDs, results):\n",
    "\t\t\t\t# initialize the list of output predictions\n",
    "\t\t\t\toutput = []\n",
    "\n",
    "\t\t\t\t# loop over the results and add them to the list of\n",
    "\t\t\t\t# output predictions\n",
    "\t\t\t\tfor (imagenetID, label, prob) in resultSet:\n",
    "\t\t\t\t\tr = {\"label\": label, \"probability\": float(prob)}\n",
    "\t\t\t\t\toutput.append(r)\n",
    "\n",
    "\t\t\t\t# store the output predictions in the database, using\n",
    "\t\t\t\t# the image ID as the key so we can fetch the results\n",
    "\t\t\t\tdb.set(imageID, json.dumps(output))\n",
    "\n",
    "\t\t\t# remove the set of images from our queue\n",
    "\t\t\tdb.ltrim(IMAGE_QUEUE, len(imageIDs), -1)\n",
    "\n",
    "\t\t# sleep for a small amount\n",
    "\t\ttime.sleep(SERVER_SLEEP)\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "\t# initialize the data dictionary that will be returned from the\n",
    "\t# view\n",
    "\tdata = {\"success\": False}\n",
    "\n",
    "\t# ensure an image was properly uploaded to our endpoint\n",
    "\tif flask.request.method == \"POST\":\n",
    "\t\tif flask.request.files.get(\"image\"):\n",
    "\t\t\t# read the image in PIL format and prepare it for\n",
    "\t\t\t# classification\n",
    "\t\t\timage = flask.request.files[\"image\"].read()\n",
    "\t\t\timage = Image.open(io.BytesIO(image))\n",
    "\t\t\timage = prepare_image(image, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "\n",
    "\t\t\t# ensure our NumPy array is C-contiguous as well,\n",
    "\t\t\t# otherwise we won't be able to serialize it\n",
    "\t\t\timage = image.copy(order=\"C\")\n",
    "\n",
    "\t\t\t# generate an ID for the classification then add the\n",
    "\t\t\t# classification ID + image to the queue\n",
    "\t\t\tk = str(uuid.uuid4())\n",
    "\t\t\td = {\"id\": k, \"image\": base64_encode_image(image)}\n",
    "\t\t\tdb.rpush(IMAGE_QUEUE, json.dumps(d))\n",
    "\n",
    "\t\t\t# keep looping until our model server returns the output\n",
    "\t\t\t# predictions\n",
    "\t\t\twhile True:\n",
    "\t\t\t\t# attempt to grab the output predictions\n",
    "\t\t\t\toutput = db.get(k)\n",
    "\n",
    "\t\t\t\t# check to see if our model has classified the input\n",
    "\t\t\t\t# image\n",
    "\t\t\t\tif output is not None:\n",
    " \t\t\t\t\t# add the output predictions to our data\n",
    " \t\t\t\t\t# dictionary so we can return it to the client\n",
    "\t\t\t\t\toutput = output.decode(\"utf-8\")\n",
    "\t\t\t\t\tdata[\"predictions\"] = json.loads(output)\n",
    "\n",
    "\t\t\t\t\t# delete the result from the database and break\n",
    "\t\t\t\t\t# from the polling loop\n",
    "\t\t\t\t\tdb.delete(k)\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t\t# sleep for a small amount to give the model a chance\n",
    "\t\t\t\t# to classify the input image\n",
    "\t\t\t\ttime.sleep(CLIENT_SLEEP)\n",
    "\n",
    "\t\t\t# indicate that the request was a success\n",
    "\t\t\tdata[\"success\"] = True\n",
    "\n",
    "\t# return the data dictionary as a JSON response\n",
    "\treturn flask.jsonify(data)\n",
    "\n",
    "# if this is the main thread of execution first load the model and\n",
    "# then start the server\n",
    "if __name__ == \"__main__\":\n",
    "\t# load the function used to classify input images in a *separate*\n",
    "\t# thread than the one used for main classification\n",
    "\tprint(\"* Starting model service...\")\n",
    "\tt = Thread(target=classify_process, args=())\n",
    "\tt.daemon = True\n",
    "\tt.start()\n",
    "\n",
    "\t# start the web server\n",
    "\tprint(\"* Starting web service...\")\n",
    "\tapp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### simple_request.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# python simple_request.py\n",
    "\n",
    "# import the necessary packages\n",
    "import requests\n",
    "\n",
    "# initialize the Keras REST API endpoint URL along with the input\n",
    "# image path\n",
    "KERAS_REST_API_URL = \"http://localhost:5000/predict\"\n",
    "IMAGE_PATH = \"jemma.png\"\n",
    "\n",
    "# load the input image and construct the payload for the request\n",
    "image = open(IMAGE_PATH, \"rb\").read()\n",
    "payload = {\"image\": image}\n",
    "\n",
    "# submit the request\n",
    "r = requests.post(KERAS_REST_API_URL, files=payload).json()\n",
    "\n",
    "# ensure the request was sucessful\n",
    "if r[\"success\"]:\n",
    "\t# loop over the predictions and display them\n",
    "\tfor (i, result) in enumerate(r[\"predictions\"]):\n",
    "\t\tprint(\"{}. {}: {:.4f}\".format(i + 1, result[\"label\"],\n",
    "\t\t\tresult[\"probability\"]))\n",
    "\n",
    "# otherwise, the request failed\n",
    "else:\n",
    "\tprint(\"Request failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "* [A scalable Keras + deep learning REST API](https://www.pyimagesearch.com/2018/01/29/scalable-keras-deep-learning-rest-api/)\n",
    "* [An introduction to the Flask Python web app framework](https://opensource.com/article/18/4/flask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
