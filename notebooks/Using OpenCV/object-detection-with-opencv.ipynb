{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with OpenCV\n",
    "Object detection, as implement here, will not only categorize what is in an image is\n",
    "but also where the object is as well by placing bounding box around the object.\n",
    "\n",
    "For object detection, we'll be using deep learning using a Single Shot Detectors and MobileNets.\n",
    "When combined together these methods can be used for super fast, real-time object detection\n",
    "on a resource constrained device like the Raspberry Pi.\n",
    "\n",
    "Research this\n",
    "* [Basic motion detection and tracking with Python and OpenCV](http://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/)\n",
    "* [Object Tracking using OpenCV (C++/Python)](https://www.learnopencv.com/object-tracking-using-opencv-cpp-python/)\n",
    "* [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)\n",
    "* [YOLO Object Detection with OpenCV](https://www.pyimagesearch.com/2018/11/12/yolo-object-detection-with-opencv/)\n",
    "* [In-Browser object detection using YOLO and TensorFlow.js](https://towardsdatascience.com/in-browser-object-detection-using-yolo-and-tensorflow-js-d2a2b7429f7c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python deep_learning_object_detection.py --image images/example_01.jpg --prototxt MobileNetSSD_deploy.prototxt.txt --model MobileNetSSD_deploy.caffemodel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# minimum probability to filter weak detections\n",
    "min_confidence = 0.2\n",
    "\n",
    "# initialize the list of class labels MobileNet SSD was trained to\n",
    "# detect, then generate a set of bounding box colors for each class\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\",\n",
    "           \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\",\n",
    "           \"pottedplant\", \"sheep\",\"sofa\", \"train\", \"tvmonitor\"]\n",
    "COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"/home/jeff/Jupyter-Notebooks/src/object-detection-deep-learning/MobileNetSSD_deploy.prototxt.txt\",\n",
    "                               \"/home/jeff/Jupyter-Notebooks/src/object-detection-deep-learning/MobileNetSSD_deploy.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] computing object detections 0.073041 seconds\n"
     ]
    }
   ],
   "source": [
    "# load the input image and construct an input blob for the image\n",
    "# by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "# (note: normalization is done via the authors of the MobileNet SSD\n",
    "# implementation)\n",
    "#image = cv2.imread(\"/home/jeff/Jupyter-Notebooks/src/object-detection-deep-learning/images/example_03.jpg\")\n",
    "#image = cv2.imread(\"/home/jeff/Pictures/Lenna.jpg\")\n",
    "#image = cv2.imread(\"/home/jeff/Pictures/eagle.png\")\n",
    "#image = cv2.imread(\"/home/jeff/Pictures/jemma.png\")\n",
    "image = cv2.imread(\"/home/jeff/Pictures/people-walking-above-1.png\")\n",
    "\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(image, 0.007843, (300, 300), 127.5)\n",
    "\n",
    "# pass the blob through the network and obtain the detections and predictions\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "detections = net.forward()\n",
    "end = time.time()\n",
    "print(\"[INFO] computing object detections {:.5} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] bird: 74.14%\n",
      "[INFO] detection labeling took 0.0010839 seconds\n"
     ]
    }
   ],
   "source": [
    "# loop over the detections\n",
    "start = time.time()\n",
    "for i in np.arange(0, detections.shape[2]):\n",
    "    # extract the confidence (i.e., probability) associated with the prediction\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "\n",
    "    # filter out weak detections by ensuring the `confidence` is\n",
    "    # greater than the minimum confidence\n",
    "    if confidence > min_confidence:\n",
    "        # extract the index of the class label from the `detections`,\n",
    "        # then compute the (x, y)-coordinates of the bounding box for\n",
    "        # the object\n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        # display the prediction\n",
    "        label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "        print(\"[INFO] {}\".format(label))\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY), COLORS[idx], 2)\n",
    "        y = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "        cv2.putText(image, label, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "end = time.time()\n",
    "print(\"[INFO] detection labeling took {:.5} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the output image\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* [Object detection with deep learning and OpenCV](http://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/)\n",
    "* [Real-time object detection with deep learning and OpenCV](http://www.pyimagesearch.com/2017/09/18/real-time-object-detection-with-deep-learning-and-opencv/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
