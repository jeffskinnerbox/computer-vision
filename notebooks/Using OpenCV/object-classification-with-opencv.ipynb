{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Classification with OpenCV\n",
    "OpenCV is an open source software library/toolbox with APIs in many programming languages.\n",
    "It contains a collection of tools that are state-of-the-art in image processing and computer vision.\n",
    "\n",
    "OpenCV 3.3.0 come with a highly improved deep learning module(`cv2.dnn`).\n",
    "This module now supports a number of deep learning frameworks, including Caffe, TensorFlow, and Torch/PyTorch.\n",
    "These frameworks provide pre-trained deep learning models so you can simply load a model from disk, pre-process an input image, and pass the image through the network and obtain the output classifications.\n",
    "\n",
    "spiecifically for for image classification by using GoogLeNet trained network from Caffe model zoo.\n",
    "\n",
    "[ImageNet](http://www.image-net.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python deep_learning_with_opencv.py --image images/jemma.png --prototxt bvlc_googlenet.prototxt --model bvlc_googlenet.caffemodel --labels synset_words.txt`\n",
    "\n",
    "`python deep_learning_with_opencv.py --image src/deep-learning-opencv/images/jemma.png --prototxt src/deep-learning-opencv/bvlc_googlenet.prototxt --model src/deep-learning-opencv/bvlc_googlenet.caffemodel --labels src/deep-learning-opencv/synset_words.txt`\n",
    "\n",
    "* `--image` : The path to the input image\n",
    "* `--prototxt` : The path to the Caffe “deploy” prototxt file\n",
    "* `--model` : The pre-trained Caffe model (i.e,. the network weights themselves)\n",
    "* `--labels` : The path to ImageNet labels (i.e., “syn-sets”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading model...\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# load the input image from disk\n",
    "image = cv2.imread(\"src/deep-learning-opencv/images/jemma.png\")\n",
    "\n",
    "# load the class labels from disk\n",
    "rows = open(\"src/deep-learning-opencv/synset_words.txt\")\n",
    "classes = [r[r.find(\" \") + 1:].split(\",\")[0] for r in rows]\n",
    "\n",
    "# our CNN requires fixed spatial dimensions for our input image(s)\n",
    "# so we need to ensure it is resized to 224x224 pixels while\n",
    "# performing mean subtraction (104, 117, 123) to normalize the input;\n",
    "# after executing this command our \"blob\" now has the shape:\n",
    "# (1, 3, 224, 224)\n",
    "blob = cv2.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(\"src/deep-learning-opencv/bvlc_googlenet.prototxt\", \\\n",
    "                               \"src/deep-learning-opencv/bvlc_googlenet.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] classification took 0.06398 seconds\n"
     ]
    }
   ],
   "source": [
    "# set the blob as input to the network and perform a forward-pass to obtain our output classification\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "preds = net.forward()\n",
    "end = time.time()\n",
    "print(\"[INFO] classification took {:.5} seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort the indexes of the probabilities in descending order (higher probabilitiy first)\n",
    "# and grab the top-5 predictions\n",
    "idxs = np.argsort(preds[0])[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 1. label: beagle\n",
      ", probability: 0.81137\n",
      "[INFO] 2. label: Labrador retriever\n",
      ", probability: 0.031416\n",
      "[INFO] 3. label: bluetick\n",
      ", probability: 0.023929\n",
      "[INFO] 4. label: EntleBucher\n",
      ", probability: 0.017507\n",
      "[INFO] 5. label: Greater Swiss Mountain dog\n",
      ", probability: 0.01444\n"
     ]
    }
   ],
   "source": [
    "# loop over the top-5 predictions and display them\n",
    "for (i, idx) in enumerate(idxs):\n",
    "    # draw the top prediction on the input image\n",
    "    if i == 0:\n",
    "        text = \"Label: {}, {:.2f}%\".format(classes[idx], preds[0][idx] * 100)\n",
    "        cv2.putText(image, text, (5, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # display the predicted label + associated probability to the console\n",
    "    print(\"[INFO] {}. label: {}, probability: {:.5}\".format(i + 1, classes[idx], preds[0][idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script\n",
    "Here is a Python script that is the equalivent to the code above.\n",
    "\n",
    "```python\n",
    "# USAGE\n",
    "# python deep_learning_with_opencv.py --image images/jemma.png --prototxt bvlc_googlenet.prototxt --model bvlc_googlenet.caffemodel --labels synset_words.txt  #noqa\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", required=True, help=\"path to input image\")\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True, help=\"path to Caffe 'deploy' prototxt file\")       #noqa\n",
    "ap.add_argument(\"-m\", \"--model\", required=True, help=\"path to Caffe pre-trained model\")               #noqa\n",
    "ap.add_argument(\"-l\", \"--labels\", required=True, help=\"path to ImageNet labels (i.e., syn-sets)\")     #noqa\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# load the input image from disk\n",
    "image = cv2.imread(args[\"image\"])\n",
    "\n",
    "# load the class labels from disk\n",
    "rows = open(args[\"labels\"]).read().strip().split(\"\\n\")\n",
    "classes = [r[r.find(\" \") + 1:].split(\",\")[0] for r in rows]\n",
    "\n",
    "# our CNN requires fixed spatial dimensions for our input image(s)\n",
    "# so we need to ensure it is resized to 224x224 pixels while\n",
    "# performing mean subtraction (104, 117, 123) to normalize the input;\n",
    "# after executing this command our \"blob\" now has the shape:\n",
    "# (1, 3, 224, 224)\n",
    "blob = cv2.dnn.blobFromImage(image, 1, (224, 224), (104, 117, 123))\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "\n",
    "# set the blob as input to the network and perform a forward-pass to\n",
    "# obtain our output classification\n",
    "net.setInput(blob)\n",
    "start = time.time()\n",
    "preds = net.forward()\n",
    "end = time.time()\n",
    "print(\"[INFO] classification took {:.5} seconds\".format(end - start))\n",
    "\n",
    "# sort the indexes of the probabilities in descending order (higher\n",
    "# probabilitiy first) and grab the top-5 predictions\n",
    "idxs = np.argsort(preds[0])[::-1][:5]\n",
    "\n",
    "# loop over the top-5 predictions and display them\n",
    "for (i, idx) in enumerate(idxs):\n",
    "    # draw the top prediction on the input image\n",
    "    if i == 0:\n",
    "        text = \"Label: {}, {:.2f}%\".format(classes[idx], preds[0][idx] * 100)\n",
    "        cv2.putText(image, text, (5, 25),  cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)              #noqa\n",
    "\n",
    "    # display the predicted label + associated probability to the console\n",
    "    print(\"[INFO] {}. label: {}, probability: {:.5}\".format(i + 1, classes[idx], preds[0][idx]))       #noqa\n",
    "\n",
    "# display the output image\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.waitKey(0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* [Deep Learning with OpenCV](http://www.pyimagesearch.com/2017/08/21/deep-learning-with-opencv/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
