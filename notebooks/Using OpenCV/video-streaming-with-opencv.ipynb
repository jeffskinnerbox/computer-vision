{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Video Streaming Using Python and OpenCV\n",
    "This is a [Flask](http://flask.pocoo.org/)\n",
    "web server that uses a streaming response\n",
    "to provide a stream of video frames captured from a camera in\n",
    "[MotionJPEG](https://en.wikipedia.org/wiki/Motion_JPEG).\n",
    "This format is very simple and not the most efficient,\n",
    "but has the advantage that all browsers support it natively and without any client-side scripting required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Requests and Responses\n",
    "When video streaming, you want to send an enormous amount of data to the client,\n",
    "much more than you want to keep in memory.\n",
    "But when you are generating the data on the fly as in video,\n",
    "how do you send that back to the client without the roundtrip to the filesystem?\n",
    "\n",
    "Streaming is a technique in which the server provides the response to a request in chunks.\n",
    "This stream of data can be created and manipulated incrementally,\n",
    "and provides an interface for reading or writing asynchronous chunks of data,\n",
    "only a subset of which might be available in memory at any given time.\n",
    "\n",
    "By default, HTTP streaming is disabled and HTTP request and response\n",
    "payloads are written to a buffer in memory before they are processed.\n",
    "You can change this behavior by enabling streaming.\n",
    "With streaming enabled, request and response payloads are streamed without modification to the client app\n",
    "(for responses) and the target endpoint (for requests). \n",
    "\n",
    "Streaming responses allow the page that made the original request to start working\n",
    "with the response as soon as the first chunk of data is available,\n",
    "and potentially use parsers that are optimized for streaming to progressively display the content.\n",
    "\n",
    "* [Stream Your Way to Immediate Responses](https://developers.google.com/web/updates/2016/06/sw-readablestreams)\n",
    "* [Streaming requests and responses](http://docs.apigee.com/api-services/content/enabling-streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CAMERA=opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `base_camera.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "try:\n",
    "    from greenlet import getcurrent as get_ident\n",
    "except ImportError:\n",
    "    try:\n",
    "        from thread import get_ident\n",
    "    except ImportError:\n",
    "        from _thread import get_ident\n",
    "\n",
    "\n",
    "class CameraEvent(object):\n",
    "    \"\"\"An Event-like class that signals all active clients when a new frame is\n",
    "    available.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.events = {}\n",
    "\n",
    "    def wait(self):\n",
    "        \"\"\"Invoked from each client's thread to wait for the next frame.\"\"\"\n",
    "        ident = get_ident()\n",
    "        if ident not in self.events:\n",
    "            # this is a new client\n",
    "            # add an entry for it in the self.events dict\n",
    "            # each entry has two elements, a threading.Event() and a timestamp\n",
    "            self.events[ident] = [threading.Event(), time.time()]\n",
    "        return self.events[ident][0].wait()\n",
    "\n",
    "    def set(self):\n",
    "        \"\"\"Invoked by the camera thread when a new frame is available.\"\"\"\n",
    "        now = time.time()\n",
    "        remove = None\n",
    "        for ident, event in self.events.items():\n",
    "            if not event[0].isSet():\n",
    "                # if this client's event is not set, then set it\n",
    "                # also update the last set timestamp to now\n",
    "                event[0].set()\n",
    "                event[1] = now\n",
    "            else:\n",
    "                # if the client's event is already set, it means the client\n",
    "                # did not process a previous frame\n",
    "                # if the event stays set for more than 5 seconds, then assume\n",
    "                # the client is gone and remove it\n",
    "                if now - event[1] > 5:\n",
    "                    remove = ident\n",
    "        if remove:\n",
    "            del self.events[remove]\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Invoked from each client's thread after a frame was processed.\"\"\"\n",
    "        self.events[get_ident()][0].clear()\n",
    "\n",
    "\n",
    "class BaseCamera(object):\n",
    "    thread = None  # background thread that reads frames from camera\n",
    "    frame = None  # current frame is stored here by background thread\n",
    "    last_access = 0  # time of last client access to the camera\n",
    "    event = CameraEvent()\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Start the background camera thread if it isn't running yet.\"\"\"\n",
    "        if BaseCamera.thread is None:\n",
    "            BaseCamera.last_access = time.time()\n",
    "\n",
    "            # start background frame thread\n",
    "            BaseCamera.thread = threading.Thread(target=self._thread)\n",
    "            BaseCamera.thread.start()\n",
    "\n",
    "            # wait until frames are available\n",
    "            while self.get_frame() is None:\n",
    "                time.sleep(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `camera_opencv.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "#from base_camera import BaseCamera\n",
    "\n",
    "\n",
    "class Camera(BaseCamera):\n",
    "    video_source = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def set_video_source(source):\n",
    "        Camera.video_source = source\n",
    "\n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        camera = cv2.VideoCapture(Camera.video_source)\n",
    "        if not camera.isOpened():\n",
    "            raise RuntimeError('Could not start camera.')\n",
    "\n",
    "        while True:\n",
    "            # read current frame\n",
    "            _, img = camera.read()\n",
    "\n",
    "            # encode as a jpeg image and return it\n",
    "            yield cv2.imencode('.jpg', img)[1].tobytes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `camera_pi.py`\n",
    "\n",
    "This cell should be disabled when the Jupyter isn't running on a Raspberry Pi.\n",
    "\n",
    ">**NOTE:** Using Jupyter notebook you can click on a cell, press `esc` and then `r`.\n",
    "That converts it to a \"raw\" cell.\n",
    "You can use `esc` + `y` to convert it back a operating cell."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import io\n",
    "import time\n",
    "import picamera\n",
    "#from base_camera import BaseCamera\n",
    "\n",
    "\n",
    "class Camera(BaseCamera):\n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        with picamera.PiCamera() as camera:\n",
    "            # let camera warm up\n",
    "            time.sleep(2)\n",
    "\n",
    "            stream = io.BytesIO()\n",
    "            for foo in camera.capture_continuous(stream, 'jpeg', use_video_port=True):\n",
    "                # return current frame\n",
    "                stream.seek(0)\n",
    "                yield stream.read()\n",
    "\n",
    "                # reset stream for next frame\n",
    "                stream.seek(0)\n",
    "                stream.truncate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `camera.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#from base_camera import BaseCamera\n",
    "\n",
    "base = '/home/jeff/Jupyter-Notebooks/src/flask-video-streaming/'\n",
    "\n",
    "class Camera(BaseCamera):\n",
    "    \"\"\"An emulated camera implementation that streams a repeated sequence of\n",
    "    files 1.jpg, 2.jpg and 3.jpg at a rate of one frame per second.\"\"\"\n",
    "    imgs = [open(base + f + '.jpg', 'rb').read() for f in ['1', '2', '3']]\n",
    "\n",
    "    @staticmethod\n",
    "    def frames():\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "            yield Camera.imgs[int(time.time()) % 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CAMERA=opencv\n",
    "\n",
    "#!/usr/bin/env python\n",
    "from importlib import import_module\n",
    "import os\n",
    "import jinja2\n",
    "from flask import Flask, render_template, Response\n",
    "\n",
    "# import camera driver\n",
    "#if os.environ.get('CAMERA'):\n",
    "#    Camera = import_module('camera_' + os.environ['CAMERA']).Camera\n",
    "#else:\n",
    "#    from camera import Camera\n",
    "\n",
    "# Raspberry Pi camera module (requires picamera package)\n",
    "# from camera_pi import Camera\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# creating a new template loader and then assigning it to the jinja_loader\n",
    "# attribute on the Flask application.\n",
    "# ChoiceLoader will search for a named template in the order of the loaders,\n",
    "# stopping on the first match. \n",
    "my_loader = jinja2.ChoiceLoader([\n",
    "    app.jinja_loader,\n",
    "    jinja2.FileSystemLoader('/home/jeff/Jupyter-Notebooks/src/flask-video-streaming/templates'),\n",
    "])\n",
    "app.jinja_loader = my_loader\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    \"\"\"Video streaming home page.\"\"\"\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "def gen(camera):\n",
    "    \"\"\"Video streaming generator function.\"\"\"\n",
    "    while True:\n",
    "        frame = camera.get_frame()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')\n",
    "\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    \"\"\"Video streaming route. Put this in the src attribute of an img tag.\"\"\"\n",
    "    return Response(gen(Camera()),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port='9000', threaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "* [Flask Video Streaming Revisited](https://blog.miguelgrinberg.com/post/flask-video-streaming-revisited)\n",
    "* [An introduction to the Flask Python web app framework](https://opensource.com/article/18/4/flask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
